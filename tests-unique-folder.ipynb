{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54bf31c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Processando imagens em: /media/williancaddd/CODES/WORKSPACE-FIOTEC/eggs-count-algorithms/article/analisar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2025-05-13 15:16:33.381675640 [W:onnxruntime:, transformer_memcpy.cc:83 ApplyImpl] 4 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processada: paleta-1-25 - IA.jpg ‚Äî Objetos finais: 16\n",
      "‚úÖ Processada: paleta-10-4 - IA.jpg ‚Äî Objetos finais: 4\n",
      "‚úÖ Processada: paleta-140-5 - IA.jpg ‚Äî Objetos finais: 6\n",
      "‚úÖ Processada: paleta-146-4 - IA.jpg ‚Äî Objetos finais: 5\n",
      "‚úÖ Processada: paleta-16-4 - IA.jpg ‚Äî Objetos finais: 3\n",
      "‚úÖ Processada: paleta-17-8 - IA.jpg ‚Äî Objetos finais: 15\n",
      "‚úÖ Processada: paleta-2-2 - IA.jpg ‚Äî Objetos finais: 2\n",
      "‚úÖ Processada: paleta-2-4 - IA.jpg ‚Äî Objetos finais: 7\n",
      "‚úÖ Processada: paleta-203-1 - IA.jpg ‚Äî Objetos finais: 1\n",
      "‚úÖ Processada: paleta-268-3 - IA.jpg ‚Äî Objetos finais: 4\n",
      "‚úÖ Processada: paleta-285-1 - IA.jpg ‚Äî Objetos finais: 3\n",
      "‚úÖ Processada: paleta-33-12 - IA.jpg ‚Äî Objetos finais: 10\n",
      "‚úÖ Processada: paleta-340-9 - IA.jpg ‚Äî Objetos finais: 19\n",
      "‚úÖ Processada: paleta-4-11 - IA.jpg ‚Äî Objetos finais: 19\n",
      "‚úÖ Processada: paleta-4-5 - IA.jpg ‚Äî Objetos finais: 7\n",
      "‚úÖ Processada: paleta-5-20 - IA.jpg ‚Äî Objetos finais: 26\n",
      "‚úÖ Processada: paleta-50-13 - IA.jpg ‚Äî Objetos finais: 22\n",
      "‚úÖ Processada: paleta-9-137 - IA.jpg ‚Äî Objetos finais: 211\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from skimage import exposure\n",
    "from typing import Tuple\n",
    "import logging\n",
    "\n",
    "logging.getLogger(\"ultralytics\").setLevel(logging.ERROR)\n",
    "\n",
    "# ========= VARI√ÅVEIS DE CONFIGURA√á√ÉO =========\n",
    "INPUT_FOLDER = \"/media/williancaddd/CODES/WORKSPACE-FIOTEC/eggs-count-algorithms/article/analisar\"  # ‚úÖ Altere aqui\n",
    "MODEL_PATH = \"/media/williancaddd/CODES/WORKSPACE-FIOTEC/eggs-count-algorithms/yolo-train/eggs-scanner-image.v2i.yolov11/runs/detect/train2/weights/best-train2.onnx\"  # ‚úÖ Altere aqui\n",
    "WINDOW_SIZE = 254\n",
    "CONFIDENCE_THRESHOLD = 0.5\n",
    "IOU_THRESHOLD = 0.8\n",
    "# ============================================\n",
    "\n",
    "PATTERN = re.compile(r\"(.*)\\.(png|jpg|jpeg)$\", re.IGNORECASE)\n",
    "\n",
    "def iou(boxA, boxB):\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
    "    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
    "    unionArea = boxAArea + boxBArea - interArea\n",
    "    return interArea / unionArea if unionArea > 0 else 0\n",
    "\n",
    "def filter_overlapping_boxes(boxes, threshold=IOU_THRESHOLD):\n",
    "    filtered = []\n",
    "    for box in boxes:\n",
    "        if all(iou(box, kept) < threshold for kept in filtered):\n",
    "            filtered.append(box)\n",
    "    return filtered\n",
    "\n",
    "class ImageProcessor:\n",
    "    def __init__(self, model: YOLO, window_size: int = WINDOW_SIZE, confidence_threshold: float = CONFIDENCE_THRESHOLD) -> None:\n",
    "        self.window_size = window_size\n",
    "        self.model = model\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "\n",
    "    def load_image(self, image_path: str) -> np.ndarray:\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"N√£o foi poss√≠vel carregar a imagem: {image_path}\")\n",
    "        return image\n",
    "\n",
    "    def normalize_square(self, square: np.ndarray) -> np.ndarray:\n",
    "        return exposure.adjust_gamma(square, gamma=1.5)\n",
    "\n",
    "    def process_image(self, image_path: str, output_folder: str) -> None:\n",
    "        image = self.load_image(image_path)\n",
    "        img_height, img_width, channels = image.shape\n",
    "        padded_height = ((img_height + self.window_size - 1) // self.window_size) * self.window_size\n",
    "        padded_width = ((img_width + self.window_size - 1) // self.window_size) * self.window_size\n",
    "        padded_image = np.zeros((padded_height, padded_width, channels), dtype=image.dtype)\n",
    "        padded_image[:img_height, :img_width, :] = image\n",
    "        annotated_image = padded_image.copy()\n",
    "\n",
    "        all_boxes = []\n",
    "\n",
    "        for y in range(0, padded_height, self.window_size):\n",
    "            for x in range(0, padded_width, self.window_size):\n",
    "                window = padded_image[y:y + self.window_size, x:x + self.window_size]\n",
    "                processed_window = self.normalize_square(window)\n",
    "                results = self.model(processed_window, verbose=False)\n",
    "                boxes = results[0].boxes\n",
    "\n",
    "                if boxes and boxes.xyxy is not None:\n",
    "                    for box in boxes:\n",
    "                        score = float(box.conf[0]) if box.conf is not None else 0.0\n",
    "                        if score < self.confidence_threshold:\n",
    "                            continue\n",
    "                        x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "                        global_box = [x + x1, y + y1, x + x2, y + y2]\n",
    "                        all_boxes.append(global_box)\n",
    "\n",
    "        final_boxes = filter_overlapping_boxes(all_boxes)\n",
    "\n",
    "        for box in final_boxes:\n",
    "            x1, y1, x2, y2 = box\n",
    "            cv2.rectangle(annotated_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            label = \"egg\"\n",
    "            cv2.putText(annotated_image, label, (x1, max(y1 - 10, 10)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "        final_image = annotated_image[:img_height, :img_width]\n",
    "\n",
    "        base_name, ext = os.path.splitext(os.path.basename(image_path))\n",
    "        output_name = f\"{base_name} - IA{ext}\"\n",
    "        output_path = os.path.join(output_folder, output_name)\n",
    "        cv2.imwrite(output_path, final_image)\n",
    "        print(f\"‚úÖ Processada: {output_name} ‚Äî Objetos finais: {len(final_boxes)}\")\n",
    "\n",
    "\n",
    "def load_model_safe(model_path: str) -> YOLO:\n",
    "    try:\n",
    "        model = YOLO(model_path)\n",
    "        dummy = np.zeros((256, 256, 3), dtype=np.uint8)\n",
    "        model(dummy)\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        if model_path.endswith(\".onnx\"):\n",
    "            print(f\"‚ö†Ô∏è Erro ao carregar modelo ONNX: {e}\")\n",
    "            fallback_path = model_path.replace(\".onnx\", \".pt\")\n",
    "            print(f\"üîÅ Tentando carregar fallback: {fallback_path}\")\n",
    "            return YOLO(fallback_path)\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(f\"üìÇ Processando imagens em: {INPUT_FOLDER}\")\n",
    "    os.makedirs(INPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "    model = load_model_safe(MODEL_PATH)\n",
    "    processor = ImageProcessor(model)\n",
    "\n",
    "    image_files = [f for f in os.listdir(INPUT_FOLDER) if PATTERN.match(f)]\n",
    "\n",
    "    for filename in sorted(image_files):\n",
    "        full_path = os.path.join(INPUT_FOLDER, filename)\n",
    "        try:\n",
    "            processor.process_image(full_path, INPUT_FOLDER)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro ao processar {filename}: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
