{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQUARE_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções de processamento de imagem\n",
    "\n",
    "def adjust_exposure(image, gamma=1.0):\n",
    "    invGamma = 21.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "def increase_brightness_contrast(image, alpha=1.0, beta=0):\n",
    "    new_image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    return new_image\n",
    "\n",
    "def enhance_color(image):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hsv[:, :, 1] = cv2.multiply(hsv[:, :, 1], 1.5)\n",
    "    enhanced_image = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    return enhanced_image\n",
    "\n",
    "\n",
    "def apply_clahe(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    clahe = cv2.createCLAHE(clipLimit=0.1, tileGridSize=(8, 8))\n",
    "    clahe_applied = clahe.apply(gray)\n",
    "    clahe_applied = cv2.cvtColor(clahe_applied, cv2.COLOR_GRAY2BGR)\n",
    "    return clahe_applied\n",
    "\n",
    "def remove_noise_rbg(image):\n",
    "    return cv2.fastNlMeansDenoisingColored(image, None, 3, 3, 7, 21)\n",
    "\n",
    "def remove_granular_noise(image):\n",
    "    denoised = cv2.bilateralFilter(image, 15, 75, 75) \n",
    "    return denoised\n",
    "\n",
    "def highlight_edges(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "    edges_colored = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n",
    "    highlighted = cv2.addWeighted(image, 1.2, edges_colored, 0.2, 0)\n",
    "    return highlighted\n",
    "\n",
    "\n",
    "\n",
    "def process_square(square):\n",
    "    color_image = cv2.cvtColor(square, cv2.COLOR_RGBA2BGR)\n",
    "    bright_contrast = increase_brightness_contrast(color_image, alpha=-12, beta=50)\n",
    "    adjusted = adjust_exposure(bright_contrast, 30)\n",
    "    denoised = remove_noise_rbg(adjusted)\n",
    "    denoised_granular = remove_granular_noise(denoised)\n",
    "    enhanced = enhance_color(denoised_granular)\n",
    "    highlighted = highlight_edges(enhanced)\n",
    "    return highlighted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para segmentação baseada nas regras propostas\n",
    "def segment_image(image):\n",
    "    # Segmentação baseada no canal vermelho da imagem\n",
    "    red_channel = image[:, :, 2]\n",
    "    _, segmented_image = cv2.threshold(red_channel, 100, 255, cv2.THRESH_BINARY)\n",
    "    return segmented_image\n",
    "\n",
    "# Função de filtragem por tamanho (remover objetos menores que 30 pixels)\n",
    "def filter_by_size(image, min_size=30):\n",
    "    contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    filtered_image = np.zeros_like(image)\n",
    "    \n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area >= min_size:\n",
    "            cv2.drawContours(filtered_image, [contour], -1, 255, thickness=cv2.FILLED)\n",
    "    \n",
    "    return filtered_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções de detecção e contagem de objetos vermelhos\n",
    "\n",
    "def detect_red_objects(square):\n",
    "    \"\"\"Detecta objetos na faixa de cor vermelha em um quadrado da imagem no espaço RGB.\"\"\"\n",
    "    # Definir intervalos para a cor vermelha no espaço RGB\n",
    "    lower_red1 = np.array([100, 0, 0])  # Vermelho mais escuro\n",
    "    upper_red1 = np.array([255, 80, 80])  # Vermelho mais claro\n",
    "    \n",
    "    # Criar uma máscara para o intervalo de vermelho\n",
    "    mask = cv2.inRange(square, lower_red1, upper_red1)\n",
    "    \n",
    "    # Aplicar a máscara na imagem original\n",
    "    red_objects = cv2.bitwise_and(square, square, mask=mask)\n",
    "    \n",
    "    return red_objects, mask\n",
    "\n",
    "def count_objects_in_red_range(square, plot=False):\n",
    "    \"\"\"Conta o número de objetos vermelhos em um quadrado da imagem e ignora objetos menores que 50 pixels.\"\"\"\n",
    "    red_objects, mask = detect_red_objects(square)\n",
    "    \n",
    "    # Encontrar contornos (objetos) na máscara binarizada\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    contour_img = square.copy()\n",
    "    cv2.drawContours(contour_img, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "    if plot:\n",
    "        # Plotagem\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        ax[0].imshow(square)\n",
    "        ax[0].set_title(\"Imagem Original\")\n",
    "        ax[1].imshow(mask, cmap='gray')\n",
    "        ax[1].set_title(\"Máscara Vermelha\")\n",
    "        ax[2].imshow(contour_img)\n",
    "        ax[2].set_title(\"Contornos Detectados\")\n",
    "        plt.show()\n",
    "\n",
    "    return len(contours), contour_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Funções de processamento de imagem por quadrados\n",
    "\n",
    "def divide_and_process_image(image):\n",
    "    img_height, img_width, _ = image.shape\n",
    "    total_objects = 0\n",
    "    processed_squares = []\n",
    "    no_processed_squares = []\n",
    "\n",
    "    for y in range(0, img_height, SQUARE_SIZE):\n",
    "        for x in range(0, img_width, SQUARE_SIZE):\n",
    "            square = image[y:y + SQUARE_SIZE, x:x + SQUARE_SIZE]\n",
    "            processed_square = process_square(square)\n",
    "            no_processed_squares.append({\"square\": square})\n",
    "            num_objects, contours_img = count_objects_in_red_range(processed_square)\n",
    "            processed_squares.append({\"square\": processed_square, \"contours_img\": contours_img, \"num_objects\": num_objects})\n",
    "            total_objects += num_objects\n",
    "\n",
    "    return processed_squares, no_processed_squares, img_height, img_width, total_objects\n",
    "\n",
    "def reconstruct_image(squares, img_height, img_width):\n",
    "    reconstructed_image = np.zeros((img_height, img_width, 3), dtype=np.uint8)\n",
    "\n",
    "    count = 0\n",
    "    for y in range(0, img_height, SQUARE_SIZE):\n",
    "        for x in range(0, img_width, SQUARE_SIZE):\n",
    "            square = squares[count][\"square\"]\n",
    "            h, w, _ = square.shape\n",
    "            padded_square = np.zeros((SQUARE_SIZE, SQUARE_SIZE, 3), dtype=np.uint8)\n",
    "            padded_square[:h, :w] = square # Preenche o quadrado com a imagem processada\n",
    "\n",
    "            reconstructed_image[y:y + h, x:x + w] = padded_square[:h, :w]\n",
    "            count += 1\n",
    "\n",
    "    return reconstructed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.310] global loadsave.cpp:241 findDecoder imread_('/media/williancarddd/NVME/fiotec/AETrampa/aedes_eggs_data/images/172-1.jpeg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /croot/opencv-suite_1722029125240/work/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# resize 4k image\u001b[39;00m\n\u001b[1;32m      7\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path)\n\u001b[0;32m----> 8\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(image, (\u001b[38;5;241m3840\u001b[39m, \u001b[38;5;241m2160\u001b[39m))\n\u001b[1;32m     10\u001b[0m processed_squares, no_processed_squares, img_height, img_width, total_objects \u001b[38;5;241m=\u001b[39m divide_and_process_image(image)\n\u001b[1;32m     11\u001b[0m reconstructed_image \u001b[38;5;241m=\u001b[39m reconstruct_image(processed_squares, img_height, img_width)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /croot/opencv-suite_1722029125240/work/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
     ]
    }
   ],
   "source": [
    "# Execução do pipeline\n",
    "\n",
    "image_path = '/media/williancarddd/NVME/fiotec/AETrampa/aedes_eggs_data/images/172-1.jpeg'\n",
    "\n",
    "# resize 4k image\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.resize(image, (3840, 2160))\n",
    "\n",
    "processed_squares, no_processed_squares, img_height, img_width, total_objects = divide_and_process_image(image)\n",
    "reconstructed_image = reconstruct_image(processed_squares, img_height, img_width)\n",
    "\n",
    "# Salvar a imagem reconstruída\n",
    "cv2.imwrite('reconstructed_image.jpg', reconstructed_image)\n",
    "\n",
    "print(f\"Total de objetos vermelhos na imagem: {total_objects}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot squadre with most objects\n",
    "max_objects = 0\n",
    "max_index = 0\n",
    "for i, square in enumerate(processed_squares):\n",
    "    if square[\"num_objects\"] > max_objects:\n",
    "        max_objects = square[\"num_objects\"]\n",
    "        max_index = i\n",
    "\n",
    "square = processed_squares[1][\"square\"]\n",
    "contours_img = processed_squares[max_index][\"contours_img\"]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax[0].imshow(square)\n",
    "ax[0].set_title(\"Quadrado com mais objetos\")\n",
    "ax[1].imshow(contours_img)\n",
    "ax[1].set_title(\"Contornos detectados\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar a imagem original e a reconstruída\n",
    "fig, ax = plt.subplots(1, 2, figsize=(25, 10))\n",
    "ax[0].imshow(reconstructed_image)\n",
    "ax[0].set_title(\"Imagem Reconstruída\")\n",
    "ax[1].imshow(cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB))\n",
    "ax[1].set_title(\"Imagem Original\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
