{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 330 slices.\n",
      "Detecções realizadas: 43\n",
      "Processado paleta2_60.png: 43 objetos encontrados.\n",
      "Performing prediction on 396 slices.\n",
      "Detecções realizadas: 61\n",
      "Processado arm 43 108 ovos.jpg: 61 objetos encontrados.\n",
      "Performing prediction on 320 slices.\n",
      "Detecções realizadas: 11\n",
      "Processado paleta4_20.png: 11 objetos encontrados.\n",
      "Performing prediction on 352 slices.\n",
      "Detecções realizadas: 24\n",
      "Processado paleta7_32.png: 24 objetos encontrados.\n",
      "Performing prediction on 330 slices.\n",
      "Detecções realizadas: 11\n",
      "Processado paleta8_0.png: 11 objetos encontrados.\n",
      "Performing prediction on 363 slices.\n",
      "Detecções realizadas: 10\n",
      "Processado paleta6_12.png: 10 objetos encontrados.\n",
      "Performing prediction on 363 slices.\n",
      "Detecções realizadas: 35\n",
      "Processado paleta1_41.png: 35 objetos encontrados.\n",
      "Performing prediction on 352 slices.\n",
      "Detecções realizadas: 19\n",
      "Processado paleta5_29.png: 19 objetos encontrados.\n",
      "Performing prediction on 330 slices.\n",
      "Detecções realizadas: 41\n",
      "Processado paleta3_18.png: 41 objetos encontrados.\n",
      "Relatório salvo em /media/williancaddd/CODES/WORKSPACE-FIOTEC/eggs-count-algorithms/base-4/report.txt\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import hashlib\n",
    "from skimage import exposure\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "# Importa as funções do SAHI para sliced inference\n",
    "from sahi.predict import get_sliced_prediction\n",
    "from sahi import AutoDetectionModel\n",
    "\n",
    "# Constante para o tamanho da janela (utilizada como dimensão do slice)\n",
    "WINDOW_SIZE = 254\n",
    "\n",
    "class ImageProcessor:\n",
    "    def __init__(self, model_path: str, window_size: int = WINDOW_SIZE) -> None:\n",
    "        \"\"\"\n",
    "        Inicializa o processador de imagem.\n",
    "\n",
    "        :param model_path: Caminho para o modelo de detecção de objetos.\n",
    "        :param window_size: Tamanho da janela (slice) para o processamento.\n",
    "        \"\"\"\n",
    "        self.window_size: int = window_size\n",
    "        self.model_path: str = model_path\n",
    "        self.image: Optional[np.ndarray] = None\n",
    "        self.processed_image: Optional[np.ndarray] = None\n",
    "        self.total_objects: int = 0\n",
    "\n",
    "    def load_image(self, image_path: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Carrega uma imagem do disco e converte de BGR para RGB.\n",
    "\n",
    "        :param image_path: Caminho para o arquivo de imagem.\n",
    "        :return: Imagem em formato RGB.\n",
    "        :raises ValueError: Se a imagem não for carregada.\n",
    "        \"\"\"\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Não foi possível carregar a imagem: {image_path}\")\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    def normalize_image(self, image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Ajusta o contraste da imagem usando correção gama.\n",
    "\n",
    "        :param image: Imagem a ser normalizada.\n",
    "        :return: Imagem com contraste ajustado.\n",
    "        \"\"\"\n",
    "        return exposure.adjust_gamma(image, gamma=1.5)\n",
    "\n",
    "    def apply_sahi_pipeline(self) -> None:\n",
    "        \"\"\"\n",
    "        Processa a imagem carregada utilizando o SAHI para sliced inference.\n",
    "        O SAHI fatiará a imagem, realizará a detecção em cada slice e unirá os resultados.\n",
    "        \"\"\"\n",
    "        if self.image is None:\n",
    "            raise ValueError(\"Nenhuma imagem foi carregada para processamento.\")\n",
    "\n",
    "        # Pré-processa a imagem (ex.: normalização)\n",
    "        processed_input = self.normalize_image(self.image)\n",
    "\n",
    "        # Instancia o modelo de detecção utilizando o AutoDetectionModel do SAHI\n",
    "        detection_model = AutoDetectionModel.from_pretrained(\n",
    "            model_type=\"ultralytics\",\n",
    "            model_path=self.model_path,\n",
    "            confidence_threshold=0.3,\n",
    "            device=\"cpu\"  # ou 'cuda:0'\n",
    "        )\n",
    "\n",
    "        # Executa a predição fatiada\n",
    "        result = get_sliced_prediction(\n",
    "            image=processed_input,\n",
    "            detection_model=detection_model,\n",
    "            slice_height=self.window_size,\n",
    "            slice_width=self.window_size,\n",
    "            overlap_height_ratio=0.2,\n",
    "            overlap_width_ratio=0.2\n",
    "        ) \n",
    "        print(f\"Detecções realizadas: {len(result.object_prediction_list)}\")\n",
    "\n",
    "        # Exporta os visuais para um diretório temporário\n",
    "        temp_folder = \"temp_visuals\"\n",
    "        os.makedirs(temp_folder, exist_ok=True)\n",
    "        result.export_visuals(export_dir=temp_folder)\n",
    "        annotated_img_path = os.path.join(temp_folder, \"prediction_visual.png\")\n",
    "        \n",
    "        # Carrega a imagem anotada (convertendo para RGB)\n",
    "        annotated = cv2.imread(annotated_img_path)\n",
    "        if annotated is None:\n",
    "            raise ValueError(\"Não foi possível carregar a imagem anotada exportada pelo SAHI.\")\n",
    "        self.processed_image = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
    "        self.total_objects = len(result.object_prediction_list)\n",
    "\n",
    "    def show_results(self) -> None:\n",
    "        \"\"\"\n",
    "        Exibe a imagem original e a imagem final processada (anotada com as detecções).\n",
    "        \"\"\"\n",
    "        if self.image is None or self.processed_image is None:\n",
    "            raise ValueError(\"Imagens não disponíveis para exibição.\")\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(20, 15))\n",
    "        axes[0].imshow(self.image)\n",
    "        axes[0].set_title(\"Imagem Original\")\n",
    "        axes[0].axis(\"off\")\n",
    "        axes[1].imshow(self.processed_image)\n",
    "        axes[1].set_title(f\"Imagem Processada Final\\nObjetos: {self.total_objects}\")\n",
    "        axes[1].axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def process_folder(self, folder_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Processa todas as imagens de uma pasta, salva os resultados e gera um relatório.\n",
    "\n",
    "        :param folder_path: Caminho para a pasta que contém as imagens.\n",
    "        \"\"\"\n",
    "        report: List[Tuple[str, int]] = []\n",
    "        image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        for filename in image_files:\n",
    "            full_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                self.image = self.load_image(full_path)\n",
    "            except ValueError as e:\n",
    "                print(e)\n",
    "                continue\n",
    "\n",
    "            self.apply_sahi_pipeline()\n",
    "            report.append((filename, self.total_objects))\n",
    "            print(f\"Processado {filename}: {self.total_objects} objetos encontrados.\")\n",
    "\n",
    "            # Salva a imagem processada em uma subpasta \"processed\"\n",
    "            processed_output_folder = os.path.join(folder_path, \"processed\")\n",
    "            os.makedirs(processed_output_folder, exist_ok=True)\n",
    "            output_image_path = os.path.join(processed_output_folder, f\"processed_{filename}\")\n",
    "            # self.processed_image já é um numpy array em RGB\n",
    "            cv2.imwrite(output_image_path, cv2.cvtColor(self.processed_image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        # Gera o relatório e salva em um arquivo txt\n",
    "        report_path = os.path.join(folder_path, \"report.txt\")\n",
    "        with open(report_path, \"w\") as f:\n",
    "            f.write(\"+===================================+\\n\")\n",
    "            f.write(\"Filename - Objetos\\n\")\n",
    "            f.write(f\"Modelo: {os.path.basename(self.model_path)}\\n\")\n",
    "            f.write(\"+===================================+\\n\")\n",
    "            for filename, count in report:\n",
    "                f.write(f\"{filename} - {count}\\n\")\n",
    "            f.write(\"+===================================+\\n\")\n",
    "        print(f\"Relatório salvo em {report_path}\")\n",
    "\n",
    "def main() -> None:\n",
    "    # Defina os caminhos para o modelo e para a pasta de imagens\n",
    "    model_path = '/media/williancaddd/CODES/WORKSPACE-FIOTEC/eggs-count-algorithms/draft-actual/best-v1.pt'\n",
    "    folder_path = '/media/williancaddd/CODES/WORKSPACE-FIOTEC/eggs-count-algorithms/base-4'\n",
    "    \n",
    "    processor = ImageProcessor(model_path=model_path)\n",
    "    processor.process_folder(folder_path)\n",
    "    # Para visualizar os resultados individualmente, descomente a linha abaixo:\n",
    "    # processor.show_results()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
